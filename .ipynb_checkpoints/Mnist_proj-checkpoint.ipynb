{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = mnist['data'],mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3.  18.\n",
      "  18.  18. 126. 136. 175.  26. 166. 255. 247. 127.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  30.  36.  94. 154. 170. 253.\n",
      " 253. 253. 253. 253. 225. 172. 253. 242. 195.  64.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  49. 238. 253. 253. 253. 253. 253.\n",
      " 253. 253. 253. 251.  93.  82.  82.  56.  39.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  18. 219. 253. 253. 253. 253. 253.\n",
      " 198. 182. 247. 241.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  80. 156. 107. 253. 253. 205.\n",
      "  11.   0.  43. 154.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.  14.   1. 154. 253.  90.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 139. 253. 190.\n",
      "   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  11. 190. 253.\n",
      "  70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  35. 241.\n",
      " 225. 160. 108.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  81.\n",
      " 240. 253. 253. 119.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  45. 186. 253. 253. 150.  27.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.  16.  93. 252. 253. 187.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0. 249. 253. 249.  64.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  46. 130. 183. 253. 253. 207.   2.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  39. 148.\n",
      " 229. 253. 253. 253. 250. 182.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  24. 114. 221. 253.\n",
      " 253. 253. 253. 201.  78.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  23.  66. 213. 253. 253. 253.\n",
      " 253. 198.  81.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  18. 171. 219. 253. 253. 253. 253. 195.\n",
      "  80.   9.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  55. 172. 226. 253. 253. 253. 253. 244. 133.  11.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0. 136. 253. 253. 253. 212. 135. 132.  16.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit = x.loc[34].to_numpy(dtype ='float32')\n",
    "some_digit_image = some_digit.reshape(28,28) # Reshaping it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(some_digit_image,cmap = matplotlib.cm.binary,interpolation = \"nearest\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "6000     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "6001     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "6002     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "6003     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "6004     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "6995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "6996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "6997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "6998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "6999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "      pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "6000      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "6001      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "6002      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "6003      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "6004      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "6995      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "6996      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "6997      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "6998      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "6999      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "6000       0.0       0.0       0.0       0.0       0.0  \n",
       "6001       0.0       0.0       0.0       0.0       0.0  \n",
       "6002       0.0       0.0       0.0       0.0       0.0  \n",
       "6003       0.0       0.0       0.0       0.0       0.0  \n",
       "6004       0.0       0.0       0.0       0.0       0.0  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "6995       0.0       0.0       0.0       0.0       0.0  \n",
       "6996       0.0       0.0       0.0       0.0       0.0  \n",
       "6997       0.0       0.0       0.0       0.0       0.0  \n",
       "6998       0.0       0.0       0.0       0.0       0.0  \n",
       "6999       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[1000 rows x 784 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test =  x[0:6000],x[6000:7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test =  y[0:6000],y[6000:7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5924, 1453,  835, ...,  988, 1324, 4228])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle_index = np.random.permutation(6000)\n",
    "shuffle_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train= x_train.iloc[shuffle_index]\n",
    "y_train = y_train.iloc[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2 = (y_train == 2)\n",
    "y_test2 = (y_test == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(tol = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\data\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(tol=0.1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\data\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\data\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\data\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "a = cross_val_score(clf, x_train, y_train2, cv = 3,scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9596666666666667"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = []\n",
    "for i in range(10):\n",
    "    model.append(LogisticRegression(tol = 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\data\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\data\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\data\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\data\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\data\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\data\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\data\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\data\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\data\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\data\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    model[i].fit(x_train,(y_train  == i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a number from 0 to 5999\n",
      "55\n",
      "You entered 55\n",
      "ans is  8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOSUlEQVR4nO3df4xU9bnH8c+jFxKlgCgbgkDcWo2J3KS0mZAbS1BTbQQN0MRgSaz4c5soEWL/uMI1qUZRYtSmGkOyXLALotBYEKKmt0qakP5THQ1VEO/Fa1Zhs8KgiVCIcJXn/rEHs4Wd76xzzvzA5/1KJjNznjnzfTL64cyc7+x8zd0F4LvvrFY3AKA5CDsQBGEHgiDsQBCEHQjiX5o52Pjx472zs7OZQwKh9Pb26uDBgzZULVfYzew6Sb+TdLak/3T3FanHd3Z2qlwu5xkSQEKpVKpaq/ttvJmdLelZSbMkXS5pgZldXu/zAWisPJ/Zp0v60N0/cvfjkjZImltMWwCKlifskyTtHXR/X7btn5hZl5mVzaxcqVRyDAcgj4afjXf3bncvuXupo6Oj0cMBqCJP2PskTRl0f3K2DUAbyhP2tyRdambfN7ORkn4haWsxbQEoWt1Tb+7+lZktkvRfGph6W+PuuwrrDEChcs2zu/trkl4rqBcADcTXZYEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANB5Fqy2cx6JR2W9LWkr9y9VERTAIqXK+yZq939YAHPA6CBeBsPBJE37C7pz2b2tpl1DfUAM+sys7KZlSuVSs7hANQrb9hnuPuPJc2SdI+ZzTz1Ae7e7e4ldy91dHTkHA5AvXKF3d37susDkjZLml5EUwCKV3fYzWyUmY0+eVvSzyTtLKoxAMXKczZ+gqTNZnbyeV5w9z8V0hWaZu/evcn6qlWrcj1/T09P1donn3yS67mffvrpZL2ra8jTSJKkZ555JrnvQw89lKxPnTo1Wd++fXuyPnLkyGS9EeoOu7t/JOmHBfYCoIGYegOCIOxAEIQdCIKwA0EQdiAIc/emDVYqlbxcLjdtvCi+/PLLqrWNGzcm93300UeT9T179tTV03ddramzzz77LFkfNWpUke18o1QqqVwu21A1juxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EEQRPziJBuvr60vWr7322qq1Dz74INfYY8aMSdZvu+22ZL2zs7Nqbffu3cl9u7u7k/VGmjFjRrL+yCOPJOuNmkfPgyM7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgTBPHsbyDOPLqXn0i+77LLkvvfee2+yPnv27GT9oosuStaPHTtW99iNdO655ybrS5cuTdZnzjxt8aO2x5EdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Jgnr0NLF++PFmv9TfpEyZMqFp79dVXk/tefPHFyXpeqaWL8y4Hncf69euT9VmzZjWpk+apeWQ3szVmdsDMdg7adr6ZvW5me7LrcY1tE0Bew3kb/3tJ152y7X5J29z9UknbsvsA2ljNsLv7dkmfn7J5rqSe7HaPpHnFtgWgaPWeoJvg7v3Z7U8lVf3QaGZdZlY2s3KlUqlzOAB55T4b7wMrQ1ZdHdLdu9295O6ljo6OvMMBqFO9Yd9vZhMlKbs+UFxLABqh3rBvlbQwu71Q0pZi2gHQKDXn2c3sRUlXSRpvZvsk/UbSCkl/MLM7JH0saX4jm0TaOeecU7XW6I9O+/btS9Y3bNjQ0PFT5syZU7V2zTXXNLGT9lAz7O6+oErppwX3AqCB+LosEARhB4Ig7EAQhB0IgrADQfAnrm3gpptuStY3btyYrPf29lat3XLLLcl9e3p6kvVaSzbffvvtyfobb7yRrOdxxRVXJOvr1q2rWmvHJZUbjSM7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgTBPHsbuPLKK5P1F154IVlP/ezxli3pnxq49dZbk/UHHnggWT98+HCynsd5552XrC9btixZHz16dIHdnPk4sgNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEMyznwFmzpyZrK9du7Zq7b777kvu+/LLL+eq51FrHv35559P1mfPnl1gN999HNmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjm2c8AqSWZJenmm2+uWhs7dmxy37lz59bV03CNGzeuaq3Wb9Yzj16smkd2M1tjZgfMbOegbQ+aWZ+Z7cgu/FcB2txw3sb/XtJ1Q2z/rbtPyy6vFdsWgKLVDLu7b5f0eRN6AdBAeU7QLTKzd7O3+VU/mJlZl5mVzaxcqVRyDAcgj3rDvlLSDyRNk9Qv6clqD3T3bncvuXupo6OjzuEA5FVX2N19v7t/7e4nJK2SNL3YtgAUra6wm9nEQXd/LmlntccCaA8159nN7EVJV0kab2b7JP1G0lVmNk2SS+qV9KvGtYhajhw5UrX20ksvNbGT082fP79q7YYbbmhiJ6gZdndfMMTm1Q3oBUAD8XVZIAjCDgRB2IEgCDsQBGEHguBPXM8AR48eTdZTSzqvW7cu19i1fu55xIgRyfqxY8dyjY/icGQHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSCYZz8DPPbYY8n68uXL637uefPmJesrVqxI1hctWpSs9/X1fduW0CAc2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCObZ28DDDz+crD/77LN1P/cTTzyRrN95553J+pgxY+oeG+2FIzsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBME8exNs3749WX/qqaeS9S+++CJZnzNnTtXaXXfdldx39OjRyXqlUknW+/v7k/ULL7wwWUfz1Dyym9kUM/uLmb1vZrvMbHG2/Xwze93M9mTX4xrfLoB6Dedt/FeSfu3ul0v6N0n3mNnlku6XtM3dL5W0LbsPoE3VDLu797v7O9ntw5J2S5okaa6knuxhPZLmNahHAAX4VifozKxT0o8k/U3SBHc/+YHtU0kTquzTZWZlMyvX+vwHoHGGHXYz+56kP0pa4u6HBtfc3SX5UPu5e7e7l9y91NHRkatZAPUbVtjNbIQGgr7e3Tdlm/eb2cSsPlHSgca0CKAINafezMwkrZa0290HzxFtlbRQ0orsektDOjwDHDlyJFlPTY1J0qFDh5L1yZMnJ+vr16+vWhs1alRy31oWL16crO/atStZv/7663ONj+IMZ579J5J+Kek9M9uRbVumgZD/wczukPSxpPkN6RBAIWqG3d3/KsmqlH9abDsAGoWvywJBEHYgCMIOBEHYgSAIOxAEf+JagCeffDJZrzWPXmsufPXq1bn2T3nuueeS9c2bNyfrkyZNStZr/VQ1mocjOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwTx7AY4ePZpr/6uvvjpZr/U346n6pk2bqtYk6c0330zWjx8/nqyvXLkyWb/kkkuSdTQPR3YgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIJ59jbwyiuv5Ko30pIlS5L1WbNmNacR5MaRHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCGM767FMkrZU0QZJL6nb335nZg5LuklTJHrrM3V9rVKPtbOnSpcn6448/3tDxL7jggqq1u+++O7nvjTfemKxPnTo1WT/rLI4XZ4rhfKnmK0m/dvd3zGy0pLfN7PWs9lt3f6Jx7QEoynDWZ++X1J/dPmxmuyWllwEB0Ha+1XswM+uU9CNJf8s2LTKzd81sjZmNq7JPl5mVzaxcqVSGegiAJhh22M3se5L+KGmJux+StFLSDyRN08CRf8gFz9y9291L7l7q6OjI3zGAugwr7GY2QgNBX+/umyTJ3fe7+9fufkLSKknTG9cmgLxqht3MTNJqSbvd/alB2ycOetjPJe0svj0ARRnO2fifSPqlpPfMbEe2bZmkBWY2TQPTcb2SftWA/s4IY8eOTdZPnDjRpE6A6oZzNv6vkmyIUsg5deBMxTcigCAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQZi7N28ws4qkjwdtGi/pYNMa+Hbatbd27Uuit3oV2dtF7j7k7781NeynDW5WdvdSyxpIaNfe2rUvid7q1azeeBsPBEHYgSBaHfbuFo+f0q69tWtfEr3Vqym9tfQzO4DmafWRHUCTEHYgiJaE3cyuM7P/NrMPzez+VvRQjZn1mtl7ZrbDzMot7mWNmR0ws52Dtp1vZq+b2Z7sesg19lrU24Nm1pe9djvMbHaLeptiZn8xs/fNbJeZLc62t/S1S/TVlNet6Z/ZzexsSf8j6VpJ+yS9JWmBu7/f1EaqMLNeSSV3b/kXMMxspqR/SFrr7v+abXtc0ufuviL7h3Kcu/97m/T2oKR/tHoZ72y1oomDlxmXNE/SrWrha5foa76a8Lq14sg+XdKH7v6Rux+XtEHS3Bb00fbcfbukz0/ZPFdST3a7RwP/szRdld7agrv3u/s72e3Dkk4uM97S1y7RV1O0IuyTJO0ddH+f2mu9d5f0ZzN728y6Wt3MECa4e392+1NJE1rZzBBqLuPdTKcsM942r109y5/nxQm6081w9x9LmiXpnuztalvygc9g7TR3OqxlvJtliGXGv9HK167e5c/zakXY+yRNGXR/cratLbh7X3Z9QNJmtd9S1PtPrqCbXR9ocT/faKdlvIdaZlxt8Nq1cvnzVoT9LUmXmtn3zWykpF9I2tqCPk5jZqOyEycys1GSfqb2W4p6q6SF2e2Fkra0sJd/0i7LeFdbZlwtfu1avvy5uzf9Imm2Bs7I/6+k/2hFD1X6uljS37PLrlb3JulFDbyt+z8NnNu4Q9IFkrZJ2iPpDUnnt1Fv6yS9J+ldDQRrYot6m6GBt+jvStqRXWa3+rVL9NWU142vywJBcIIOCIKwA0EQdiAIwg4EQdiBIAg7EARhB4L4f9tKQF8Oa/9ZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "  \n",
    "    print(\"Enter a number from 0 to 5999\")\n",
    "    some_digit = int(input())\n",
    "    if(some_digit < 0 or some_digit>5999):\n",
    "        print(\"Wrong Input\")\n",
    "        exit(0)\n",
    "    print(\"You entered\",some_digit)\n",
    "    some_digit = x.loc[some_digit].to_numpy(dtype ='float32')\n",
    "    some_digit_image = some_digit.reshape(28,28)\n",
    "    plt.imshow(some_digit_image,cmap = matplotlib.cm.binary,interpolation = \"nearest\")\n",
    "    mx = 0\n",
    "    for i in range(10):\n",
    "        ex = model[i].predict_proba([some_digit])[:,1]\n",
    "        if(ex[0] > mx):\n",
    "            ans = i\n",
    "            mx = ex\n",
    "    print(\"ans is \",ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
